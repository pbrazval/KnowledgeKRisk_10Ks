%%
% Please see https://bitbucket.org/rivanvx/beamer/wiki/Home for obtaining beamer.
%%
\documentclass{beamer}
\usepackage{natbib}
\usepackage{graphicx}
\usetheme{Singapore}
\usepackage{subfig}
\usepackage{dcolumn}
\usepackage{hyperref}
\usepackage{caption}
\title[] %optional
{Using LDA to Identify Knowledge Capital Risks in Firms' Annual Reports}

\author[Pedro Vallocci] % (optional)
{Pedro H. Braz Vallocci\inst{1}}

\institute[UCSC] % (optional)
{
  \inst{1}%
  University of California, Santa Cruz
 }

\newcommand{\ffo}{dicfullmc10thr10defnob40noa1_4t}
\newcommand{\ffoviii}{dicfullmc5thr10_default_flt_8t}
\newcommand{\ffoiii}{dicfullmc5thr10_default_flt_6t}
\newcommand{\ffovi}{dicfullmc5thr10_default_flt_3t}

\newcommand{\insertfigurenoffo}[3]{
\begin{figure}[h!]
  \centering
  \includegraphics[width=#3\textwidth]{#1}
  \caption{#2}
  \label{fig:#1}
\end{figure}
}

\newcommand{\insertfigure}[2]{
\begin{figure}[h!]
  \centering
  \includegraphics[width=0.6\textwidth]{\ffo/#1}
  \centering
  \captionsetup{font=scriptsize}
  \caption{#2}
  \label{fig:#1}
\end{figure}
}

\newcommand{\insertfigureiii}[2]{
\begin{figure}[h!]
  \centering
  \includegraphics[width=0.6\textwidth]{\ffoiii/#1}
  \centering
  \captionsetup{font=scriptsize}
  \caption{#2}
  \label{fig:#1}
\end{figure}
}

\newcommand{\insertfigurevi}[2]{
\begin{figure}[h!]
  \centering
  \includegraphics[width=0.6\textwidth]{\ffovi/#1}
  \centering
  \captionsetup{font=scriptsize}
  \caption{#2}
  \label{fig:#1}
\end{figure}
}


\begin{document}
\frame{\titlepage}

\begin{frame}
\frametitle{Outline}
\tableofcontents
\end{frame}

\section{Introduction}

\begin{frame}
\frametitle{Research Question}
\begin{itemize}
\item Can we measure the risk of knowledge capital by performing topic analysis on firms' self-reported risk factors?
%\item If so, do agents price in different risks for knowledge-heavy firms?
%\item More generally, can topic modeling the firms' self-declared risk factor provide a sensible categorization of firms by risk?
\end{itemize}
\end{frame}

\begin{frame}\frametitle{Motivation (1)}
\begin{itemize}	
\item \textit{Knowledge capital} represents a firm's cumulative investment in research and development (R\&D) and constitutes a significant portion (38 to 47\%) of its overall value (\cite{Belo2019-iz}).
\item Knowledge capital differs from physical capital in terms of its risk profile:
\begin{itemize}
\item Higher adjustment costs (Belo et al., 2019) and greater depreciation (Li et al., 2020)
\item Jumps in cash flows arising from innovation breakthroughs \cite{Andrei2019-bh}
\end{itemize}
\end{itemize}
\end{frame}

\begin{frame}\frametitle{Motivation (2)}
\begin{figure}[h!]
  \centering
  \includegraphics[width=0.8\textwidth]{\ffo/amazon_nov01.png}
  \scriptsize
  \caption{On November 13th, 2001, Amazon was granted the patent ``use of electronic shopping carts to generate personal recommendations"}
  \label{data_steps}
\end{figure}
\end{frame}

\begin{frame}
\frametitle{Motivation (3)}
  \begin{itemize}
  \item Existing measures are insufficient for identifying  knowledge-related risks in firms:
\begin{itemize}
\item Knowledge capital intensity, where KK is measured by firm's accumulated R\&D
\item Intangible capital intensity, where IK is measured by firm's accumulated SG\&A
\item Patent intensity 
\end{itemize}
\item SEC requires firms to file annual reports (10-K)
\begin{itemize}
\item The language of the mandatorily reported firm risk factors (1A) can vary widely across firms 
\end{itemize}
\end{itemize}
\end{frame}

\begin{frame}
\frametitle{Excerpts of 10-Ks for different firms}

``... Additionally, our product candidates can fail at any stage of the R\&D process, and may not receive regulatory approval even after many years of R\&D... " Pfizer, 2023\\
	
\vspace{2\baselineskip}
	``...Citi has experienced (...) negative impacts to its businesses, results of operations and financial condition as a result of various macroeconomic, geopolitical and other challenges, uncertainties and volatility...." Citigroup, 2023
\end{frame}

\begin{frame}
\frametitle{Summary of findings}
\begin{itemize}
	\item Utilizing Latent Dirichlet Allocation (LDA) on a dataset of 10-K risk factors reveals a distinct topic related to knowledge capital risk, referred to as $Topic_{kk}$. %This finding is consistent across various settings, including the analysis with four topics
	\item The ranking of firms based on $Topic_{kk}$ significantly diverges from traditional measures such as accumulated R\&D investments, patent market value, and workforce skills.
	\item  Aligning with existing research, firms with a greater dependency on innovation for generating cash flows exhibit a higher kurtosis in returns. This indicates an elevated tail risk
\end{itemize}
\end{frame}

\begin{frame}
\frametitle{Literature review}
\small 
\begin{itemize}
\item Previous papers have delved into the impact of intangible capital for firmsâ€™ investment decisions and valuation: Peters and Taylor (2015), Crouzet and Eberly (2019, 2021)
\item Knowledge capital, intellectual property, and their relevance for firm valuation: Koh et al. (2015), Kogan et al. (2017), Andrei et al. (2019), Belo et al. (2022), Mezzanotti and Simcoe (2023)
\item Factor models and intangible capital on asset pricing: Fama and French (1993, 2015), Eisfeldt and Papanikolaou (2011), Eisfeldt et al. (2020)
\item LDA, natural language processing, and applications to Economics: Blei et al. (2003), Manela and Moreira (2017), Gentzkow et al. (2019), Bybee et al. (2021), Babii et al. (2022), Gabaix et al. (2023)

\end{itemize}
\end{frame}

\section{Data}
\begin{frame}
\frametitle{Why LDA?}
\begin{itemize}
\item Other algorithmic text analysis methods used for concept detection include (Ash and Hansen, 2023) dictionary methods, word embeddings, and supervised methods
\item LDA is an unsupervised learning method, meaning that it learns and infers from the data without any predefined labels. Topics generated cannot be targeted towards specific concepts
\item LDA allows for concept exploration without imposing strong priors about the dictionary used and without relying on subjective human labeling, while often creating interpretable topics. \hyperlink{slide:lda}{\beamerbutton{LDA}} \hyperlink{slide:approach}{\beamerbutton{Approach}}

\end{itemize}
\end{frame}

%\begin{frame}
%  \frametitle{An example of 10-K}
%\insertfigurenoffo{apples_1a}{A slice of Apple's 10-K (Item 1A, Risk Factors)}{0.8}
%\end{frame}
 
\begin{frame}
\frametitle{1st step: Extracting textual risk factors for each firm}
\begin{itemize}
\item Downloaded from the SEC website 121,839 firm 10-Ks, filed from 2006 to 2022, resulting in approximately 1.6 TB of data. 
\item Extracted the Item 1A (Risk Factors) section from the tree-like structure (XML) of each 10-K.
\item Performed standard text cleaning
\end{itemize}
\end{frame}

%
%\begin{frame}
%\frametitle{Filtering firms (1)}
%\begin{itemize}
%\item Only ordinary common shares, traded at NYSE, AMEX, or NASDAQ, are kept (\cite{Stambaugh2016-eb}, \cite{Golubov2019-ku}):
%\begin{itemize}
%  \item I also consider only firms whose stocks were being traded at a minimum price of \$5 in 2016 dollars (\cite{Stambaugh2016-eb})
%\end{itemize}
%\end{itemize}
%\end{frame}


\begin{frame}
\frametitle{2nd step: Filtering relevant texts}
\scriptsize
    \begin{columns}[T]
    \begin{column}{0.5\textwidth}
\input{\ffo/file_counts_nocaption.tex}
    \end{column}

    \begin{column}{0.5\textwidth}
    \normalsize
    Left: count of all documents (1As) retrieved for a given year. Right: documents fulfilling all the following filtering criteria: 
    \begin{enumerate}
   \item Ordinary common shares
   \item  	Membership to NYSE, AMEX, and NASDAQ
   \item Price above \$ 5 in 2006 dollars
   \item Meaningful contents of risk factors ($>$ 200 words)
   \hyperlink{slide:nonfilingfirms}{\beamerbutton{Non-filing firms}}\hyperlink{slide:min_words}{\beamerbutton{Choosing 200 as threshold}}
    \end{enumerate}
    \end{column}
    \end{columns}
\end{frame}

\begin{frame}
\frametitle{3rd step: Converting texts to bag-of-words}
\begin{itemize}
	\item Standard lemmatization of words
	\item Dictionary contains words (1-grams, 2-grams and 3-grams) belonging to any document in the corpus, as long as they appear in at least 0.1\% of documents \hyperlink{slide:ngram_details}{\beamerbutton{N-gram details}}

	\item Texts are converted to a bag-of-words format
\end{itemize}
\end{frame}



\begin{frame}
\frametitle{Topic modeling}
\begin{itemize}
\item I apply unsupervised topic modeling (Latent Dirichlet Allocation) to the whole corpus of documents containing risk factors for different firm-years, setting as parameter the number \textit{k} of topics, and providing the dictionary previously created.
\begin{itemize}
  \item The choice of \textit{k} is often done \textit{ad hoc} and driven by interpretability (\cite{Gentzkow2019-va})
\end{itemize}
\end{itemize}
\end{frame}

\begin{frame}
	\insertfigure{wordclouds}{Word clouds for each topic in the 4-topic setting. In the following steps, I define $Topic\_kk$ as Topic 0.}
\end{frame}

%\begin{frame}
%  \frametitle{Results}
%  \label{results}
%  \begin{itemize}
%  \item   \href{https://htmlpreview.github.io/?https://github.com/pbrazval/LDA_10Ks/blob/main/dicfullmc10thr10defnob5noa0_8_3t.html}{3-topic model}
%  \item   \href{https://htmlpreview.github.io/?https://github.com/pbrazval/LDA_10Ks/blob/main/dicfullmc10thr10defnob5noa0_8_4t.html}{4-topic model}
%  \item   \href{https://htmlpreview.github.io/?https://github.com/pbrazval/LDA_10Ks/blob/main/dicfullmc10thr10defnob5noa0_8_5t.html}{5-topic model}
%  \item   \href{https://htmlpreview.github.io/?https://github.com/pbrazval/LDA_10Ks/blob/main/dicfullmc10thr10defnob5noa0_8_6t.html}{6-topic model}
%  \item   \href{https://htmlpreview.github.io/?https://github.com/pbrazval/LDA_10Ks/blob/main/dicfullmc10thr10defnob5noa0_8_8t.html}{8-topic model}
%  \item   \href{https://htmlpreview.github.io/?https://github.com/pbrazval/LDA_10Ks/blob/main/dicfullmc10thr10defnob5noa0_8_10t.html}{10-topic model}
%  \item In all these models, knowledge-related words are concentrated in a few topics. 
%  \item Based on the correlation with skill and patent activity in the data, the 4-topic model has provided the best results so far.   \hyperlink{slide:meantiy_details}{\beamerbutton{Mean Topic Intensity by Year}}\hyperlink{robthree}{\beamerbutton{Results with 3 topics}}\hyperlink{robsix}{\beamerbutton{Results with 6 topics}}
%\end{itemize}
%\end{frame}


\begin{frame}
  \frametitle{A sample of the topic map}
The LDA analysis yields a topic map, which assigns topic intensity loadings to each firm-year.
   \tiny
  \input{\ffo/sample_map.tex}
\end{frame}


\section{Empirical Analysis}

\begin{frame}
  \frametitle{Comparison with Preexisting Measures of Knowledge Capital Risk}
  In the upcoming slides, I will present a comparison of risk factor topic loadings with established measures in the field:
  \begin{itemize}
    \item Firm patent intensity, where firm's patent value is measured by \cite{Kogan2017-fx}) 
    \item Industry skill level, as measured by \cite{Belo2017-qi}. 
    \item Knowledge capital as quantified by \cite{Peters2017-fl}.
  \end{itemize}
  Textual risk measure offers distinct insights when compared to these traditional metrics.
\end{frame}

\begin{frame}
\frametitle{Correlation of textual-based measure of KK risk with preexisting measures} 

\begin{table}[!htbp]  
  \label{fig:bytech} 
  \scriptsize 
\begin{tabular}{@{\extracolsep{0pt}} D{.}{.}{3} D{.}{.}{-3} D{.}{.}{-3} } 
\\[-1.8ex]\hline 
\hline \\[-1.8ex] 
\multicolumn{1}{c}{Topic} & \multicolumn{1}{c}{Skill (ind.)} & \multicolumn{1}{c}{Patent intensity (firm)} \\ 
\hline \\[-1.8ex]
\multicolumn{1}{c}{Raw Materials} & -0.542 & -0.064 \\ 
\multicolumn{1}{c}{Software} & 0.534 & 0.163 \\ 
\multicolumn{1}{c}{Financials} & -0.017 & -0.131 \\ 
\multicolumn{1}{c}{KK} & 0.099 & 0.062 \\ 
\hline \\[-1.8ex] 
\end{tabular} 
\end{table} 
\begin{itemize}
	\item Skill is defined as the average industry skill for each firm, as measured \cite{Belo2017-qi}.
	\item Patent intensity is defined for each firm-year as $\frac{\text{Accum. Patent Value}}{\text{Total assets}}$, where patent value is measured by \cite{Kogan2017-fx}.
	\item The topic-based KK risk measure offers distinct insights when compared to these traditional metrics.
\end{itemize}
\end{frame}


%\begin{frame}
%\frametitle{Topic\_kk vs. patent activity}
%       \begin{columns}
%          \column{0.6\linewidth}
%             \begin{figure}[h!]
%		  \centering
%		  \includegraphics[width=1.2\textwidth]{\ffo/heatmap_patents.png}
%		  \captionsetup{font=scriptsize}
%		  \label{fig:firmsbypathm}
%			\end{figure}
%          \column{0.4\linewidth}
%          \scriptsize
%              \begin{itemize}
%              \item Here, I count the co-occurrences of topic\_kk quartiles and accumulated patent-related firm market value.
%              \item \cite{Kogan2017-fx} use stock market data to estimate the value of all patents filed by public firms since 1926.
%			  \item The vertical axis is divided by yearly defined quartiles of:
%			  \begin{equation}
%  				\frac{\text{Yearly Accum. Patent Value}}{\text{Total assets}}
%				\end{equation}
%			\end{itemize}
%	  \end{columns} 
%\end{frame}

%\begin{frame}
%\frametitle{Topic\_kk vs. Skill}
%\scriptsize
%\insertfigure{heatmap}{Correlation between different topics and average industry skill, as measured by \cite{Belo2017-qi}. \cite{Belo2017-qi} define industry skill as defined as the share of high-skill workers measured by the BLS; a "high-skill" occupation has Specific Vocational Preparation $\geq 7$ or over two years of preparation.} 
%\end{frame}

\begin{frame}
\frametitle{Comparison with preexisting measures: Knowledge capital intensity}
%\frametitle{Topic\_kk vs. Knowledge Capital}
\scriptsize
\begin{columns}
\column{0.6\linewidth}	
\begin{figure}[h!]
\centering
\includegraphics[width=1.2\textwidth]{\ffo/topicvskkpt_hm.png}
\label{fig:topicvskkpt_hm}
\end{figure}
\column{0.4\linewidth}	
\begin{itemize}
	\item KK measure for firm i, year t, follows \cite{Peters2017-fl}:
	\begin{align*}
		KK_{it} &= (1-\delta_{R\&D}) KK_{i,t-1}\\
		&+R\&D_{i,t}
	\end{align*}
	\item KK intensity normalizes KK by firm's total assets.
	\item Sorting by KK topic loadings provides different information than by KK intensity
\end{itemize}
\end{columns}
\end{frame}

%\begin{frame}
%  \frametitle{Implications for asset pricing}
%In the following slides:
%\begin{itemize}
%	\item I integrate the firms with its weekly returns since 2006.
%	\item For each week and each group, I compute the asset-weighted return and accumulate it.
%	\item  Distinctively, firm with a higher value of topic KK show higher values of kurtosis over time.
%\end{itemize}
%\end{frame}

\begin{frame}
\frametitle{Different topics are associated with different cross-sectional volatility patterns}
	\begin{columns}
		\column{0.6\linewidth}
			\begin{figure}[h!]
			\centering
			\includegraphics[width=1.2\textwidth]{\ffo/wsdr.jpg}
			\label{fig:wsdr}
			\end{figure}
		\column{0.4\linewidth}
		\begin{itemize}
			\scriptsize
			\item Weekly standard deviation of returns within groups, grouped by maximum topic.
			\item Higher KK risk is associated with higher return volatility
		\end{itemize}
	\end{columns}
\end{frame}

\begin{frame}
\frametitle{Heterogeneity in Kurtosis Patterns Across Different Topics}
\scriptsize 
\begin{columns}
\column{0.6\linewidth}
\begin{figure}[h!]
\centering
\includegraphics[width=0.9\textwidth]{\ffo/kurtosis_maxtopic.jpg}
\caption{Weekly Standard Deviation of Returns by Maximum Topic}
\label{fig:kurtosis_maxtopic}
\end{figure}
\column{0.4\linewidth}	
\scriptsize 
\begin{itemize}
	\item Innovation activities are often correlated with increased cash flow volatility, leading to fatter tails in return distributions.
	\item The kurtosis of daily returns is calculated for each firm-year.
	\item Averaged kurtoses are computed annually for each topic.
	\item Firms with high knowledge intensity consistently exhibit higher kurtosis compared to their peers, a trend observed since 2006.
\end{itemize}
\end{columns}
\end{frame}

\begin{frame}
\frametitle{Variation in Kurtosis Across Quartiles of $Topic\_{kk}$}
\scriptsize 
\begin{columns}
\column{0.6\linewidth}
\begin{figure}[h!]
\centering
\includegraphics[width=0.9\textwidth]{\ffo/kurtosis_ntile.jpg}
\caption{Weekly Standard Deviation of Returns by $Topic\_{kk}$ Quartiles}
\label{fig:kurtosis_ntile}
\end{figure}

\column{0.4\linewidth}	
\scriptsize 
\begin{itemize}
	\item Kurtosis is annually averaged for each group, categorized by their quartile in $Topic\_{kk}$.
	\item A consistent trend is observed: kurtosis increases with higher quartiles each year, suggesting that greater self-reported knowledge capital risk correlates with more pronounced tail risk in returns.
\end{itemize}
\end{columns}
\end{frame}


%\begin{frame}
%\frametitle{Value-weighted returns}
%\insertfigure{awawr}{Value-weighted accumulated weekly returns; grouped by quartile of topic\_kk (defined every year). Higher loadings of topic\_kk are associated with higher weekly returns, especially since 2011. }
%\end{frame}

%\begin{frame}
%\frametitle{Value-weighted returns, grouping by topic\_kk (defined for every year-ind12)}
%%\insertfigure{awawr_aggind}{Creating topic\_kk quartiles for each year-industry subset, common patterns are less interpretable. I use the 12-industry Fama-French classification.}
%\end{frame}

\begin{frame}
\small 
\frametitle{Pricing knowledge risk premium}
\begin{itemize}
\item To obtain an estimate of knowledge risk premium $\widehat{\lambda}_{kk}$ I analyze firms' weekly returns using a two-stage approach, following \cite{Goyal2012-ct}. 

\item 24 portfolios are formed, expanding \cite{Fama1993-da}. 
\begin{itemize}
	\item Firms are divided into two groups by size, dividing by NYSE's median
	\item Firms are divided into three groups by MB, dividing by NYSE's 30th and 70th percentile
	\item Firms are divided into four groups, according to their quartiles of $topic\_kk$  
\end{itemize}

\item Portfolios are rebalanced every $26^{th}$ calendar-week.
\end{itemize}
\end{frame}

\begin{frame}
\frametitle{Pricing knowledge risk premium}
For each portfolio $i$ and each week $t$, I obtain estimates of betas from the time-series regressions:
	\begin{align*}
		R_{it}-R_{F,t} &= a_i + \beta_{M, i} (R_{M,t}-R_{F,t}) + \beta_{SMB, i} SMB_t \\
		&+\beta_{HML, i} HML_t +\beta_{KKHML, i} KKHML_t \\
		&+\varepsilon_{i,t} 
	\end{align*}
\begin{itemize}
	\item Weekly estimates of $R_{F,t}$, $SMB_t$, $HML_t$ and $R_{M,t}-R_{F,t}$ are retrieved from Kenneth French's website. 
\end{itemize}
\end{frame}

\begin{frame}
\begin{itemize}
	\item The factor $KKHML_t$ is defined as a differential excess return, calculated by subtracting the return of a value-weighted portfolio of firms in the 1st quartile of KK from its equivalent in the 4th quartile of KK.
	\item I then run a cross-sectional regression of average returns on betas:
\begin{align}
\bar{R}_T=\widehat{B} \lambda+\alpha
\end{align}
\end{itemize}

\end{frame}


\begin{frame}
\tiny
\input{\ffo/summary_table.tex}
\end{frame}

\section{Next Steps}
\begin{frame}
\frametitle{Next Steps}
\begin{itemize}
    \item Further study the role of knowledge capital risk in asset pricing:
    \begin{itemize}
        \item Examine the influence of diverse tail risks on asset pricing models, referencing \cite{Kelly2014-oo}
        \item Test the results on Fama and Macbeth (1973).
        \item Integrate findings with the Fama-French five-factor model to enhance its predictive power
        \item Assess the capacity of these models to explain and predict market anomalies
    \end{itemize}
    \item Conduct robustness tests with varying numbers of topics to ensure the stability of results 
    \item Optimize hyperparameters
    \item Possible transition towards supervised learning models:
    \begin{itemize}
        \item Implement a prior for 'topic\_kk' with key terms like 'patents', 'intellectual property'.
    \end{itemize}
\end{itemize}
\end{frame}

\bibliographystyle{apecon}
\begin{frame}[allowframebreaks]
\frametitle{References}
\bibliography{mylibrary2.bib}
\end{frame}

\section{Appendix}


\begin{frame}
\frametitle{Approach}
\label{slide:approach}
\begin{itemize}
\item I employ Latent Dirichlet Allocation (LDA), a topic modeling technique, on a corpus of 121,839 firm annual reports (2006-2022), to identify latent topics.
\item By matching firms based on their CIK and PERMNO, I link the annual reports to daily stock data (aggregated weekly), Compustat data, and measures of firms' knowledge capital, accumulated patent value, and industry skill from existing literature.
%\item I observe a positive association between higher intensities of a specific topic (e.g., "topic kk") and the aforementioned measures. 
\end{itemize}
\end{frame}


\begin{frame}
\frametitle{Latent Dirichlet Allocation (LDA)}
\label{slide:lda}
\begin{itemize}
\small
\item LDA is a generative statistical model widely used for topic modeling in natural language processing (NLP).
\item It operates under the assumption that each document in a corpus is a mixture of a number of latent topics $k \in \{1, ..., K\}$, with weights $\omega_{i1}, ..., \omega_{iK}$. Each topic is assigned a word probability vector $\mathbf{\theta}_k$. 
\item Therefore, if $X_i$ is the vector of word counts with length $n_i$, 
\begin{equation}
X_i \sim \operatorname{Multinomial}\left(n_i, \omega_{i 1} \theta_1+\cdots+\omega_{i K} \theta_K\right)
\end{equation}
\item The output of LDA is a list of topics, each represented as a collection of words, and a weight distribution across these topics for each document.
\end{itemize}
\end{frame}

\begin{frame}
\frametitle{Details of n-gram construction}
\label{slide:ngram_details}
\begin{itemize}
\item n-grams need to appear at least 10 times in the corpus
\item The n-gram must achieve a ``score" of at least 10, using the scoring function from \cite{Mikolov2013-be} \hyperlink{slide:ngram_main}{\beamerbutton{Back to n-gram construction}}
\item I only keep words that have occurred at least 10 times in the whole document; and that are not too common (i.e. that have appeared in 80\% of documents or less)
\end{itemize}
\insertfigurenoffo{mikolov_formula}{Bigram scoring function}{0.3}
\end{frame}

\begin{frame}
\frametitle{Mean Topic Intensity by Year}
\label{slide:meantiy_details}
\hyperlink{results}{\beamerbutton{Back to results}}
\insertfigure{mean_tiy}{Mean Topic Intensity by Year}
\end{frame}

\begin{frame}
\label{slide:acc_ntile4kk}
\frametitle{Accumulated assets of firms in the upper quartile of topic\_kk}
\insertfigure{stackedplot_at}{Accumulated assets of firms in the upper quartile of topic\_kk}
\end{frame}

\begin{frame}
\frametitle{Filtering firms (2)}
\label{slide:nonfilingfirms}
\begin{itemize}
\item Reporting risk factors is mandatory for most firms, but there are exceptions for asset-backed issuers and smaller reporting companies.
\item Asset-backed issuers are defined as issuers whose reporting obligation arises from the registration of an offering of asset-backed securities under the Securities Act or the registration of a class of asset-backed securities.
\item Firms that are not required to disclose risk factors may leave Item 1A empty or write a placeholder text indicating that they are not required to disclose risk factors due to their nature.
\item This leads to a high frequency of 10-K filings with a significantly low number of words, as shown in Figure \ref{fig:cdf}. In the subsequent stages, 1A texts with an insufficient word count (less than 200 words) are discarded \hyperlink{slide:min_words}{\beamerbutton{Details}}.
\end{itemize}
\end{frame}


\begin{frame}
\frametitle{Filtering firms (3)}
\label{slide:min_words}
\begin{figure}
  \centering
  \subfloat[Full picture]{\includegraphics[width=0.45\textwidth]{cdf_words}\label{fig:cdf_words}}
  \hfill
  \subfloat[Detail]{\includegraphics[width=0.45\textwidth]{cdf_words_zoom}\label{fig:cdf_words_zoom}}
  \caption{Word count cumulative distribution function, for all 10-Ks filed in 2022}
  \label{fig:cdf}
\end{figure}
\end{frame}


\begin{frame}
\frametitle{The Process of Lemmatization}
\label{slide:lemma}
\begin{itemize}
\item Lemmatization is the technique of converting words to their base or root form, effectively eliminating any suffixes and inflections. This ensures semantic consistency across different forms of a word.
\begin{itemize}
  \item For instance, words like "take", "took", and "taken" are all simplified to their common root form, "take".
\end{itemize}
\item The lemmatization process in this project is carried out using the \texttt{spacy} Python library. \texttt{spacy} leverages WordNet, an extensive lexical database of English maintained by Princeton University. 
\end{itemize}
\end{frame}

\begin{frame}
\frametitle{Establishing N-grams and Constructing the Dictionary}
\label{slide:ngram_main}
\begin{itemize}
\item N-grams are defined as groupings of $n$ words appearing together at an unusually high frequency. Examples include phrases like ``New York",``patent application", and `research and development".\hyperlink{slide:ngram_details}{\beamerbutton{Details}}

\item I identified n-grams for $n \leq 3$. For dictionary and bag-of-words purposes, n-grams are treated as distinct words
\item I constructed a dictionary from the ensemble of n-gramized texts. Words were only incorporated into the dictionary if they were featured in a minimum of 0.1\% of the documents %and less than 80\% of all documents.

\item The final version of my dictionary comprises 24,973 unique words. %24,813 if 40/0.8
\end{itemize}
\normalsize
\end{frame}

\begin{frame}
\frametitle{Conversion of texts to bag-of-words}
\label{slide:bagofwords}
\begin{itemize}
\item Using the dictionary and the n-gramized texts, I convert all my texts to a bag-of-words format.
\item The bag-of-words representation ignores the order of words altogether, while keeping the count $c_{ij}$ of appearances of each word $j$ in document $i$, creating the final representation of the \textit{corpus} (\cite{Gentzkow2019-va})
\end{itemize}
\end{frame}

\begin{frame}
\label{slide:kk_by_tech}
  \frametitle{Comparing topic\_kk with high-tech sectors in the economy}
  \begin{itemize}
  \item \cite{Brown2009-zp} define the high-tech sectors of the economy as the sectors with the SIC codes 283, 357, 466, 367, 382, 384, 737 
  \input{\ffo/tpcavg_tech.tex}
\end{itemize}
 \end{frame}


\begin{frame}
\label{slide:kkrisk_by_ik}
\frametitle{Title}
       \begin{columns}
          \column{0.6\linewidth}
             \begin{figure}[h!]
		  \centering
		  \includegraphics[width=\textwidth]{\ffo/topicvsikpt_hm.png}
		  \centering
		  \captionsetup{font=scriptsize}
		  \label{fig:topicvsikpt_hm}
			\end{figure}
          \column{0.4\linewidth}
          \scriptsize
              \begin{itemize}
			  \item a
			  \item b
			\end{itemize}
	  \end{columns} 
\end{frame}

%\begin{frame}
%\frametitle{Return volatility, six topics}
%       \begin{columns}
%          \column{0.6\linewidth}
%             \begin{figure}[h!]
%		  \centering
%		  \includegraphics[width=\textwidth]{\ffovi/msdr_byg.jpg}
%		  \captionsetup{font=scriptsize}
%		  \label{fig:heatmappatents}
%			\end{figure}
%          \column{0.4\linewidth}
%          \scriptsize
%              \begin{itemize}
%			  \item a
%			  \item b
%			\end{itemize}
%	  \end{columns} 
%\end{frame}

%\begin{frame}
%\frametitle{Return volatility, three topics}
%\insertfigure{\ffovi/msdr_byg.jpg}{Value-weighted accumulated weekly returns, grouping by firms' maximum topic.}
%\end{frame}
%

\begin{frame}
\label{slide:count_ntile4kk}
\frametitle{Count of firms in the upper quartile of topic\_kk}
\insertfigure{stackedplot_n}{stackedplotn}
\end{frame}
%
%\begin{frame}
%\frametitle{5 topics}
%\begin{figure}[h!]
%		  \centering
%		  \includegraphics[width=\textwidth]{\ffo/msdr_byg_5t.jpg}
%		  \centering
%		  \captionsetup{font=scriptsize}
%		  \label{fig:topicvsikpt_hm}
%			\end{figure}
%\end{frame}
%
%\begin{frame}
%\frametitle{3 topics}
%\begin{figure}[h!]
%		  \centering
%		  \includegraphics[width=\textwidth]{\ffo/wsdr_byg_3t.jpg}
%		  \centering
%		  \captionsetup{font=scriptsize}
%		  \label{fig:topicvsikpt_hm}
%			\end{figure}
%\end{frame}


			
%			
%\begin{frame}
%\label{slide:volatility_by_maxt}
%\frametitle{Different topics are associated with different cross-sectional volatility patterns}
%\insertfigure{wsdr_byg}{Weekly standard deviation of returns within groups, grouped by maximum topic.}
%\end{frame}

%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% ROBUSTNESS TEST: 3 TOPICS
%\begin{frame}
%\label{robthree}
%\centering
%\huge\bfseries Robustness tests: 3 topics
%\hyperlink{results}{\beamerbutton{Back to results}}
%\end{frame}
%
%\begin{frame}
%  \frametitle{Defining topic\_kk}
%  \begin{itemize}
%  \item LDA creates $k$ topics and assigns them to each document of the corpus. "Patents", "intellectual property", and correlated terms tend to be concentrated in few topics.
%  \item For every topic map, I define "topic\_kk" as the topic that has the highest loading within high-tech sectors in the economy, defined as SIC codes 283, 357, 466, 367, 382, 384, 737 (\cite{Brown2009-zp}) 
%  \input{\ffoiii/tpcavg_tech.tex}
%\end{itemize}
%
%\end{frame}
%
%
%\begin{frame}
%\frametitle{Topic\_kk vs. patent activity}
%       \begin{columns}
%          \column{0.6\linewidth}
%             \begin{figure}[h!]
%		  \centering
%		  \includegraphics[width=\textwidth]{\ffoiii/firmsbypat_hm.png}
%		  \captionsetup{font=scriptsize}
%		  \label{fig:firmsbypathm}
%			\end{figure}
%          \column{0.4\linewidth}
%          \scriptsize
%              \begin{itemize}
%              \item Here, I count the co-occurrences of topic\_kk quartiles and accumulated patent-related firm market value.
%              \item \cite{Kogan2017-fx} use stock market data to estimate the value of all patents filed by public firms since 1926.
%			  \item The vertical axis is divided by yearly defined quartiles of:
%			  \begin{equation}
%  				\frac{\text{Accumulated Patent Value}}{\text{Total assets}}
%				\end{equation}
%			  \item A higher accumulated patent value is associated with higher loadings of topic\_kk.
%			\end{itemize}
%	  \end{columns} 
%\end{frame}
%
%\begin{frame}
%\frametitle{Topic\_kk vs. Knowledge Capital}
%\scriptsize
%\insertfigureiii{topicvskkpt_hm}{Correlation between quartiles of Knowledge capital,  as defined in \cite{Peters2017-fl}, vs. quartiles of topic\_kk. Higher accumulated investments in R\&D are correlated to higher loadings of topic\_kk.}
%\end{frame}
%
%\begin{frame}
%\frametitle{Topic\_kk vs. Skill}
%\scriptsize
%\insertfigureiii{heatmap}{Correlation between different topics and average industry skill, as measured by \cite{Belo2017-qi}. \cite{Belo2017-qi} define industry skill as defined as the share of high-skill workers measured by the BLS; a "high-skill" occupation has Specific Vocational Preparation $\geq 7$ or over two years of preparation.}. 
%\end{frame}
%
%\begin{frame}
%\frametitle{Value-weighted returns}
%
%\insertfigureiii{awawr}{Value-weighted accumulated weekly returns; grouped by quartile of topic\_kk (defined every year)}
%\end{frame}
%
%
%
%\begin{frame}
%\frametitle{Value-weighted returns, grouping by topic\_kk (defined for every year-ind12)}
%\insertfigureiii{awawr_aggind}{Value-weighted accumulated weekly returns}
%\end{frame}
%
%\begin{frame}
%\frametitle{Value-weighted returns, defining 4-tiles by year $\times$ ind12}
%\insertfigureiii{awawr_byg}{Value-weighted accumulated weekly returns, grouping by firms' maximum topic.}
%\end{frame}
%
%\begin{frame}
%\frametitle{Different topics are associated with different cross-sectional volatility patterns}
%\insertfigureiii{wsdr_byg}{Weekly standard deviation of returns within groups, grouped by maximum topic.}
%\end{frame}
%
%\begin{frame}
%\frametitle{Accumulated assets of firms in the upper quartile of topic\_kk}
%\insertfigureiii{stackedplot_at}{Accumulated assets of firms in the upper quartile of topic\_kk}
%\end{frame}
%
%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% ROBUSTNESS TEST: 6 TOPICS
%\begin{frame}
%\label{robsix}
%\centering
%\huge\bfseries Robustness tests: 6 topics
%\hyperlink{results}{\beamerbutton{Back to results}}
%\end{frame}
%
%\begin{frame}
%  \frametitle{Defining topic\_kk}
%  \begin{itemize}
%
%  \item For every topic map, I define "topic\_kk" as the topic that has the highest loading within high-tech sectors in the economy, defined as SIC codes 283, 357, 466, 367, 382, 384, 737 (\cite{Brown2009-zp}) 
%  \tiny
%  \input{\ffovi/tpcavg_tech.tex}
%\end{itemize}
%
%\end{frame}
%
%
%\begin{frame}
%\frametitle{Topic\_kk vs. patent activity}
%       \begin{columns}
%          \column{0.6\linewidth}
%             \begin{figure}[h!]
%		  \centering
%		  \includegraphics[width=\textwidth]{\ffovi/firmsbypat_hm.png}
%		  \captionsetup{font=scriptsize}
%		  \label{fig:firmsbypathm}
%			\end{figure}
%          \column{0.4\linewidth}
%          \scriptsize
%              \begin{itemize}
%              \item Here, I count the co-occurrences of topic\_kk quartiles and accumulated patent-related firm market value.
%              \item \cite{Kogan2017-fx} use stock market data to estimate the value of all patents filed by public firms since 1926.
%			  \item The vertical axis is divided by yearly defined quartiles of:
%			  \begin{equation}
%  				\frac{\text{Accumulated Patent Value}}{\text{Total assets}}
%				\end{equation}
%			  \item A higher accumulated patent value is associated with higher loadings of topic\_kk.
%			\end{itemize}
%	  \end{columns} 
%\end{frame}
%
%\begin{frame}
%\frametitle{Topic\_kk vs. Knowledge Capital}
%\scriptsize
%\insertfigurevi{topicvskkpt_hm}{Correlation between quartiles of Knowledge capital,  as defined in \cite{Peters2017-fl}, vs. quartiles of topic\_kk. Higher accumulated investments in R\&D are correlated to higher loadings of topic\_kk.}
%\end{frame}
%
%\begin{frame}
%\frametitle{Topic\_kk vs. Skill}
%\scriptsize
%\insertfigurevi{heatmap}{Correlation between different topics and average industry skill, as measured by \cite{Belo2017-qi}. \cite{Belo2017-qi} define industry skill as defined as the share of high-skill workers measured by the BLS; a "high-skill" occupation has Specific Vocational Preparation $\geq 7$ or over two years of preparation.}. 
%\end{frame}
%
%\begin{frame}
%\frametitle{Value-weighted returns}
%\insertfigurevi{awawr}{Value-weighted accumulated weekly returns; grouped by quartile of topic\_kk (defined every year)}
%\end{frame}
%
%
%
%\begin{frame}
%\frametitle{Value-weighted returns, grouping by topic\_kk (defined for every year-ind12)}
%\insertfigurevi{awawr_aggind}{Value-weighted accumulated weekly returns}
%\end{frame}
%
%\begin{frame}
%\frametitle{Value-weighted returns, defining 4-tiles by year $\times$ ind12}
%\insertfigurevi{awawr_byg}{Value-weighted accumulated weekly returns, grouping by firms' maximum topic.}
%\end{frame}
%
%\begin{frame}
%\frametitle{Different topics are associated with different cross-sectional volatility patterns}
%\insertfigurevi{wsdr_byg}{Weekly standard deviation of returns within groups, grouped by maximum topic.}
%\end{frame}
%
%\begin{frame}
%\frametitle{Accumulated assets of firms in the upper quartile of topic\_kk}
%\insertfigurevi{stackedplot_at}{Accumulated assets of firms in the upper quartile of topic\_kk}
%\end{frame}


\end{document}
