\documentclass[12pt, letterpaper]{article}
\usepackage{setspace} 
\usepackage{graphicx} 
\usepackage{dcolumn}
\usepackage{placeins}
\usepackage{natbib}
\usepackage{subcaption}
\usepackage{float}
\usepackage{lipsum} 
\usepackage{mathpazo}
\usepackage{hyperref}
\bibliographystyle{econ}
\hypersetup{
    colorlinks=true,%    linkcolor=blue,    filecolor=magenta,      
    urlcolor=cyan,
    citecolor=blue
}

\usepackage[letterpaper, margin=1in]{geometry}


\begin{document}
\title{Measuring Knowledge Capital Risk: Evidence from firm 10-Ks}
\author{Pedro H. Braz Vallocci \footnote{Ph.D. candidate in Economics, University of California, Santa Cruz} 
\footnote{I am very grateful to my advisor, Galina Hale, for her continuous support during my whole research process. I also thank Alonso Villacorta, Grace Gu, John Fernald, Michael Leung, Brenda Samaniego de la Parra, Chenyue Hu, Roberto Mauad, Bhavyaa Sharma, Ted Liu, Harrison Shieh, and the UCSC Macro Workshop participants for all their valuable comments.}} % 

\newcommand{\ffo}{dicfullmc10thr10defnob5noa0_8_4t}

\newcommand{\insertfigure}[3]{
\begin{figure}[H]
  \centering
  \includegraphics[width=#3\textwidth]{\ffo/#1}
  \caption{#2}
  \label{fig:#1}
\end{figure}
}

% TODO
% - Iterate with new priors until you find a fixed point. List key phrases: knowledge, innovation...
% - A better idea would be to choose number of topics with perplexity or something alike.
% - Elaborate on why existing measures are not good enough.
% - Move on to the rest of the paper to not get bogged down in the end. Take a break, come back.
% - Keep talking to Michael
% - Fin institutions are different in debt/assets and productivity measures. Not sure if I need to remove them or not. Maybe keep them and do a robustness test. 
% - Michael: use the ground truth somewhere. 

\newcommand{\tkk}{$Topic_{kk}$ }

\maketitle 

\begin{center}
For the latest version of this paper, click \href{https://github.com/pbrazval/jmdocs/blob/main/brazvallocci_jmp.pdf}{here}.
\end{center}

\begin{abstract}
    This study proposes a methodology to identify firms that are vulnerable to knowledge capital-related risks, relying on a textual analysis of the risk factors disclosed in their annual reports. Further, the paper quantifies these risks through an examination of firms' concurrent return patterns. \newline \textbf{\indent Keywords:} Innovation, firm risk factors, productivity, intangible capital, natural language processing, asset pricing \newline \textbf{\indent JEL classification:} C43, C55, D2, E22, G11, O3
\end{abstract}

\newpage 

\onehalfspacing 

\section{Introduction}



% Galina's feedback: should include:


% 1) What is the problem
% 2. What is the current answer
% 3. What do you add in this paper.

% Knowledge-capital heavy are known to have different 

% Open: Moved from the bottom following Galina's feedback (that this part needs to be in the first page). Can be better mixed with the text above/below

The transition towards a service- and knowledge-based economy has been accompanied by a sharp increase in intangible assets. Knowledge capital, conceptualized as the aggregate of a firm's investments in research and development (R\&D), has become an increasingly significant factor in the valuation of firms \citep{Belo2019-iz}. Firms endeavor to foster innovation through research, aiming to generate intellectual property that may lead to breakthroughs and augment cash flows. Concurrently, firms face the challenges of competition and product obsolescence, which can symmetrically induce sudden devaluations. The episodic nature of innovation implies that firms with substantial knowledge capital are likely to experience more volatile valuations. 

However, the existing literature has predominantly attempted to correlate the risk associated with knowledge capital to a firm's R\&D or patent intensity \citep{Andrei2019-bh}. Such classifications overlook the reality that the efficacy with which firms convert R\&D into tangible innovations—and consequently into increased cash flows—is both industry-specific and firm-specific. Moreover, patenting activities are recognized to be unevenly distributed across industries and firm sizes \citep{mezzanotti2023innovation, Li2020-xc}. 

Within this framework, several pertinent questions arise: Can we more accurately discern knowledge-related risks by conducting textual analysis of the risk factors delineated in firms' annual reports? Furthermore, if it is possible to identify knowledge-intensive firms in this manner, does this insight impact the way market participants value these entities? In essence, is there a differential in the market's risk assessment for firms with heavy knowledge capital compared to their less knowledge-intensive counterparts? This paper proposes a methodology to identify firms that are vulnerable to knowledge capital-related risks, relying on a topic analysis (LDA) of the risk factors disclosed in their annual reports. Further, the paper quantifies these risks through an examination of firms' concurrent return patterns.

Spending on intangible assets is an investment since it reduces current consumption to increase future consumption \citep{Corrado2009-kd, Corrado2009-hk}. Among the components of a firm's intangible capital are knowledge capital, brand capital, and organization capital.  In this context, \emph{brand capital} is defined as a firm's accumulated expenses in advertising \citep{Belo2019-iz}; \emph{organization capital}, as the set of an enterprise's unique systems and processes %, being positively correlated with the firm's managerial quality scores 
\citep{Eisfeldt2013-ad, Bloom2007-gl}; and \emph{knowledge capital}, as a firm's accumulated investments in R\&D.
%most notably in research and development

Accumulated R\&D expenses are considered an integral part of firm's capital in supply-side models such as \cite{Belo2013-ys}, accounting for an increasing share of public firms' valuation. Along these lines, \cite{Hall2001-ni, McGrattan2001-kc, Vitorino2014-yd, Eisfeldt2020-ec, Li2014-zp} confirm that intangible capital matters for aggregate stock market valuations and, more specifically, firm-level valuations. \cite{Corrado2009-kd} estimated total intangible capital in 2003 to be 3.6 trillion, half of which as scientific and non-scientific R\&D capital. \cite{Crouzet2022-ic} found that the omission of knowledge capital and its associated rents can explain up to 2/3 of the investment gap (the difference between marginal $q$ and average $Q$) in R\&D intense sectors such as Healthcare and Chemicals. On another note, R\&D expenditures are considered as intermediate expenses that can spur growth in models with expanding varieties \citep{Romer1990-tw} and quality ladders \citep{Grossman1991-pz, Atkeson2019-wz}.
%Notably, this form of capital exhibits a distinct risk profile compared to tangible, physical capital. For instance, companies heavily reliant on knowledge capital are more susceptible to the loss of critical personnel and modifications in patent enforcement. 



%  Moreover, endogenous growth models, such as models with expanding varieties \citep{Romer1990-tw}, and with quality ladders \citep{Grossman1991-pz, Atkeson2019-wz}, imply that research expenses can spur growth. Even though the two latter models consider R\&D as intermediate expenses, supply-side valuation models such as \cite{Belo2013-ys} argue that not only quasi-fixed physical capital and labor inputs but also knowledge and brand capital can determine a firm's market value. 



%However, equating the omission of intangible and knowledge capital to a mere mismeasurement of a firm's book value is misleading since intangible capital has unique characteristics and thus cannot be lumped together with physical capital. \cite{Autor2020-rw, Unger2019-ip} shed light on a "scale-biased technological change" in R\&D-heavy firms. Greater output scalability, the absence of geographical constraints for input sourcing or output distribution, and the greater importance of network effects lead to a "winner-takes-most" outcome in some industries (i.e., an uneven market power distribution) and a declining labor share, consistent with \cite{Barkai2020-gi}.
%
%Moreover, R\&D-driven technological innovation, while generating research externalities in the form of knowledge available to the rest of society, may also be a force for creative destruction \citep{Schumpeter1939-er} if it leads to mere resource reallocation across firms. Therefore, it is not evident that private-led innovation increases aggregate output. \citep{Kogan2017-fx, Garcia-Macia2019-mg} show that innovation has a net effect of accelerating aggregate output and that own-product improvements by incumbents are more important than creative destruction.
%
%R\&D-intensive firms are also more likely to offshore profit shifting, i.e., to license their intellectual property rights to offshore subsidiaries in order to accrue derived profits at tax-havens. Compared to non-R\&D-intensive firms (e.g., construction), it is easier to decouple the physical location of intellectual property production from its point of sale. Offshore profit shifting has grown since the 2000s, which coincides with the beginning of the productivity growth slowdown \citep{Fernald2015-io}. Adjusting for offshore profit shifting adds 2.1 log percentage points to R\&D-heavy firms, which is ten times larger than for non-R\&D. Labor productivity in R\&D-intensive firms has also grown much faster than in non-R\&D firms \citep{Guvenen2021-yh}.

The riskiness of intangible assets differs systematically from tangible ones \citep{Hansen2005-xe}. \cite{Eisfeldt2013-ad} point out that shareholders cannot entirely appropriate the cash flows from the key talent of the firm since the firm must always compensate key talent by its outside option. \cite{Eisfeldt2018-iy} shows that key talent partially owns the cash flow from intangible capital in the form of equity, finding that almost 40\% of compensation to high-skilled labor happens as equity-based pay. Finally, \cite{Ai2019-wd} predicts that collateralizable assets, which do not include some categories of intangibles, provide insurance against aggregate shocks in the economy and should earn a lower expected return.

Knowledge capital's risk characteristics set it apart from other forms of intangible capital. Firms invest on research to increase their future earnings, but not all innovations come to fruition. For example, research conducted by a pharmaceutical firm can lead to successful new drugs that lead to patent rents for several years or to no result at all. The presence of innovation-driven jumps in cash flow is related to an increased empirical dispersion of Tobin's q, and also helps explain why the relatxion between Tobin's q and aggregate investment has become tighter since the mid-1990s \citep{Andrei2019-bh}. 

Besides the uncertainty of research investments, a firm is also susceptible to writing off part of its knowledge capital due to obsolescence, e.g., when it narrowly loses a patent race \citep{Peters2017-fl}. Such competitive forces lead to R\&D capital depreciation. Depreciation rates vary over time and according to individual industry technological and competitive environments \citep{Li2020-xc}. Besides varying between industries, it is expected that depreciation rates vary across firms in the same industry, since firms' ability to materialize research into innovation and additional cash flow is also expected to be random, varying with managerial processes, employees' skills, and regulation-related uncertainty.

Knowledge capital heavy firms also are especially vulnerable to loss of key talent. \cite{Eisfeldt2013-ad} find that firms are more likely to list ``loss of key talent" as a risk factor in their 10-K reports when they have high organization capital. Firms vulnerable to loss of key talent are especially susceptible to immigration-related risks, e.g., the H-1B visa annual quota shortages \citep{Peri2015-qt}. 
%It makes sense that the same pattern is valid for knowledge capital heavy firms, which are highly dependent on specialized and scarce workforce. 

A prominent reliance on R\&D may also entail a different financial risk profile. \cite{Li2011-ay} find that the riskiness of a financially constrained firm increases with its R\&D intensity. Additionally, young, R\&D-intensive firms frequently face challenges in securing debt finance due to the unpredictable and fluctuating returns on R\&D, and the potential adverse selection and moral hazard in the R\&D financing market. Notably, fluctuations in the supply of equity finance were instrumental in shaping the R\&D surge of the 1990s \citep{Brown2009-zp}, pointing to a shared risk factor among these firms.

%. The H-1B visa, introduced with the Immigration and Nationality Act of 1990, established temporary renewable visas for college-educated specialty professional workers, most of whom work in STEM occupations. \cite{Peri2015-qt} shows that the growth in foreign-STEM workers may explain between 10 and 25\% of the aggregate productivity growth and 10\% of skill-bias growth between 1990 and 2010.

%Following previous literature on time-varying disaster risks, such as \cite{Gabaix2012-kw, Barro2006-pt, Rietz1988-ds, Gourio2012-nt} shows that increases in the risk of an economic disaster can lead to an increase in risk premia and a decrease in unemployment and output. My work will develop upon \cite{Gourio2012-nt} to consider a knowledge capital heavy economy, and investigate if agents are pricing in the risk of sudden drops in the efficiency of knowledge investment (e.g., due to shortage of skilled workforce) or sudden firm-specific write-offs ("disasters") of knowledge capital (e.g., due to weakening in patent laws).

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
% Why not sufficient
% R\&D
The current methods of identifying knowledge capital related risk across firms, deriving from uncertain outcomes of research, use proxies (accumulated R\&D, SG\&A, patent wealth) that fail to accurately describe potential volatilities in cash flows. A possible approach might involve tying knowledge capital risk to a firm's knowledge capital, normalized by its assets or another variable. However, a significant limitation is the inconsistent R\&D reporting standards across industries and firms. This inconsistency is exacerbated by some firms not disclosing their R\&D expenditure in annual reports.  Similarly, methods that merely accumulate R\&D expenses  to characterize the knowledge intensity of a firm, using the perpetual inventory method, ignore that depreciation is random and unique to each firm.

%SG&A
Another possible, and similar, approach involves tying knowledge capital risk to a firm's total intangible assets instead, typically through indirect measures like Selling, General and Administrative expenses (SG\&A). However this measure is by nature prone to considerable measurement error and includes not knowledge-related components, such as organizational capital and brand capital. This can blur the distinction between knowledge-heavy and non-knowledge-heavy firms.

%Patents
Lastly, relying on patents as a measure of a firm's knowledge intensity only tells part of the story. While patents reflect the final outcomes of R\&D investments, they do not account for the internal learning processes that take place within firms, thus potentially undervaluing those that invest heavily in internal knowledge development, even if they do not have a high patent output. Additionally, measures of patent activity, such as the one in \cite{Kogan2017-fx}, are not flawless indicators of the risks associated with R\&D-centric firms. Large firms and firms in specific industries are more prone to protecting their intellectual property, which shows that patent distribution does not directly mirror the exposure to knowledge capital risks \citep{mezzanotti2023innovation}.

\citet{Kogan2017-fx} demonstrate that the companies' market value surges within the following three days of the filing of potentially lucrative patents, that is, patents that have the potential to amplify a firm's revenue streams while simultaneously stifling competition. Yet, one must ponder whether the stock market, outside patent-filing moments, also internalizes the inherent risks of devoting a significant part of investments to a risky innovation process.

\section{Methodology and Data}

% Galina: need to add: brief summary of what is in this section. E.g. why is LDA the most appropriate technique for you?

In this paper, knowledge capital risk is defined as the unique form of risk that innovation-centric firms bear, particularly when their cash flow trajectories are influenced by the stochastic nature of research-induced innovations. This risk is inherent in the unpredictable timing and impact of such innovations on a firm's financial performance.

Methodologies for textual analysis, such as pattern detection, are diverse and multifaceted. They encompass a range of techniques from simple pattern matching to more complex algorithmic constructions of term sets, as well as the identification of prevailing topics within textual data. These methods are employed to extract meaningful patterns and trends from unstructured text.

The concept of knowledge capital risk, however, lacks an empirical "ground truth," a benchmark against which the accuracy of predictions or classifications can be validated, such as the VIX in \cite{Manela2017-lj}, used as ground truth to create a measure of news volatility dating back to 1890. Moreover, the construction of a comprehensive dictionary is complex, as the terminology can vary significantly across industries. For instance, the lexicon indicative of intellectual property concerns in pharmaceutical companies may frequently reference terms such as "clinical trials" or "regulatory compliance" within their annual reports.

In light of these complexities, my approach will leverage Latent Dirichlet Allocation (LDA) to analyze the risk factor sections within firms' 10-K filings. This method will facilitate the extraction of dominant topics that are most indicative of knowledge capital risk. 

\subsection{Latent Dirichlet Allocation (LDA)}

In this study, I use Latent Dirichlet Allocation (LDA), a topic modeling technique, to identify latent topics within firms' self-reported risk factors in a comprehensive corpus of 121,839 firm annual reports (10-Ks), covering a timespan from 2006 to 2022.


Latent Dirichlet Allocation (LDA) is a generative statistical model that is widely employed for topic modelling within the field of natural language processing (NLP). LDA relies on the assumption that each document in a given corpus can be seen as a mixture of a certain number of latent topics, denoted as $k \in {1, ..., K}$, each of which carries a particular weight, $\omega_{i1}, ..., \omega_{iK}$. Each of these topics is assigned a word probability vector, $\mathbf{\theta}_k$, defining the likelihood of each word appearing under this topic \citep{Blei2003-ay}.

Under this model, if we denote $X_i$ as the vector of word counts with length $n_i$ in the $i$th document, the word distribution in a document is modeled as a multinomial distribution. The probability of $X_i$ can be written as:

\begin{equation}
X_i \sim Multinomial\left(n_i, \omega_{i 1} \theta_1+\cdots+\omega_{i K} \theta_K\right)
\end{equation}

%This equation represents the fact that the observed words in the document are generated by a mixture of topics, with each topic contributing to the document with a certain weight.

The output of an LDA operation is twofold: firstly, it generates a list of topics, with each topic represented as a collection of words. Secondly, it offers a weight distribution across these topics for each document, indicating the degree to which each topic is present in a given document.

It is important to note that LDA is an unsupervised learning method. This means that it operates without any predefined labels, instead learning and inferring patterns directly from the data. However, this also poses a challenge, since the topics generated might not necessarily align with any intuitive description, requiring therefore post-analysis interpretation. %This characteristic makes LDA a versatile tool, able to extract valuable insights from large and complex corpora of text data.

\subsection{Data}

I retrieve the annual reports (10-Ks) for all U.S. publicly listed firms since 2013 from the Securities and Exchange Commission's EDGAR database. A 10-K is a comprehensive document that provides an overview of the company's financial performance and operations over a year, offering a detailed picture of a company's business.  To ensure transparency and accuracy, laws and regulations strictly prohibit companies from making false or misleading statements in their 10-Ks. Additionally, under the Sarbanes-Oxley Act, a company's Chief Financial Officer (CFO) and Chief Executive Officer (CEO) are required to certify the accuracy of the 10-K (\cite{SEC_Office_of_Investor_Education_and_Advocacy2011-tw}).

Item 1A of a 10-K (``Risk Factors") includes information about the most significant risks that apply to the company or its securities.  I extract the item 1A information from each 10-K using XML parsing and \texttt{BeautifulSoup}, and removed supposedly less meaningful characters such as punctuation and numbers.

\subsection{Filtering firms}

Following \cite{Golubov2019-ku, Stambaugh2016-eb}, I filter firms by considering only ordinary common shares, traded on NYSE, AMEX, and NASDAQ exchanges; and following \cite{Stambaugh2016-eb} I exclude those whose prices are less than \$5 in 2016 dollars. 

Reporting risk factors is mandatory for most firms; however, there are exceptions for asset-backed issuers and smaller reporting companies. Asset-backed issuers are defined as issuers whose reporting obligation arises from either the registration of an offering of asset-backed securities under the Securities Act or the registration of a class of asset-backed securities. Firms that are not required to disclose risk factors either leave Item 1A empty or write a placeholder text specifying that, due to their nature, they are not required to disclose risk factors. Consequently, there is an abnormal frequency of 10-K filings with a significantly low number of words, as depicted in Figure \ref{fig:cdf}. In subsequent stages, 1A texts with an insufficient word count are discarded. The threshold adopted was 200 words. The total count of filtered firms by year is shown in Table \ref{tab:file_counts}.

The next step is to convert each text in the corpus to a bag-of-words format, detailed in Appendix A.

% TODO Need to change: use min10kwords = 200


\input{\ffo/file_counts.tex} 


%Through this approach, I have observed a positive correlation between higher intensities of a specific topic, hereafter referred to as "$Topic_{kk}$", and the aforementioned measures. This suggests that firms that more frequently discuss this topic may have higher levels of knowledge capital, accumulated patent value, and industry skill.
%
%Furthermore, I have found that firms in the upper quartile of "$Topic_{kk}$" intensity have consistently outperformed their peers in terms of returns since 2006. This finding indicates a potential link between the subject matter discussed in firms' annual reports and their financial performance.



%TODO Create in R a function that receives one of the key df's 

%TODO Create in r a funciton that returns: for a given year; distr per topic; average K_int/K_int_Know per topic; average patent expenditure; average/std size  

% TODO: How many 1As per year? How many public firms in Compustat?

\subsection{Topic modeling}

Upon having the corpus and the dictionary, I employ LDA to endogenously generate topic loadings for the entire set of documents. During the model's configuration, I designate a parameter to specify the number of topics, represented as \(k\), and supply the model with the dictionary I previously created. Selecting an appropriate value for \(k\) is typically done \textit{ad hoc}, with the primary consideration being interpretability, as highlighted by Gentzkow (2019).

A representative output from this modeling approach can be viewed in Figure \ref{fig:bubble_plot}.


\insertfigure{bubble_plot}{A graphic representation of a four-topic model on firms' risk factors since 2006.}{1}

After merging a four-topic map between firms and topic intensities to firms' identifying data, I obtain a topic map as shown in Table \ref{tab:topic_map}.

\tiny
\input{\ffo/topic_map_sample.tex}
\normalsize

%\caption{The left column shows the count of all 10-Ks retrieved for a given year. The right column counts all the 10-Ks that obey to the following filtering criteria: 1) Ordinary common shares; 2) Membership to NYSE, AMEX, and NASDAQ; 3) Price above \$ 5 in 2006 dollars; 4) Meaningful 10-K contents ($>$ 200 words)} 


% TODO: Find out: what min_count to use? Does this actually make a large differnece? 

% TODO Need to change:\texttt{} re-run processes with \n detection

% TODO Need to change: re-run processes starting in 2005

% TODO Need to change: use default instead of npmi; min_count = 5; threshold = 10

\section{Results}

In this section, I validate our text-based metric, $Topic_{kk}$, by cross-referencing it with established measures from prior literature. This assessment strengthens the reliability and relevance of our metric within the broader context of knowledge capital analysis.

Finally, I examine the implications of our findings for asset pricing, discerning correlations between knowledge capital and financial performance. This sets the stage for a deeper exploration of knowledge-intensive firms' influence on the financial landscape.

\subsection{Defining $Topic_{kk}$}

For every topic map, I define $Topic_{kk}$ as the topic that has the highest loading within high-tech sectors in the economy, defined as SIC codes 283, 357, 466, 367, 382, 384, 737 (\cite{Brown2009-zp}). 

% Improve:
In the analysis below, topic intensity is defined as the average of topic loadings for all firm-year occurrences, for each case.

Table \ref{tab:bytech} shows the average topic intensity for low- and high-tech firms for a four-topic model. 

\input{\ffo/tpcavg_tech.tex}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%% Descriptive statistics
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\subsection{Descriptive statistics}

As depicted in Figure \ref{fig:mean_tiy}, the mean topic intensity per year demonstrates a steady rise in the usage of knowledge-capital related language in firms' risk factors since 2009. This upward trend underlines the increasing emphasis placed on knowledge capital within these organizations.

\insertfigure{mean_tiy}{Mean annual topic intensity}{0.7}

Quartiles for \tkk are shown in Figure \ref{fig:topickk_distr}. As the figure shows, knowledge capital risk is unevenly distributed among firms, with more than half of the firms having \tkk $< 0.25$.

\insertfigure{topickk_distr}{The histogram bars represent the frequency of $Topic_{kk}$ values, while the red dashed lines indicate the quartile dividers. }{0.7} 

Lastly, Figure \ref{fig:stackedplot_at} illustrates the accumulated assets of firms in the upper quartile of $Topic_{kk}$, which shows a clear prevalence of firms in the Business Equipment, Chemicals, and Other sectors.

% Galina: 
% Add some narrative of what these figures tell us overall (i.e. meaning), at an intuitive level. Now I am just describing what I see.

\insertfigure{stackedplot_at}{Accumulated Assets of Firms in the Upper Quartile of $Topic_{kk}$}{0.7}


\subsection{Validating the text-based metric of knowledge-intensive firms}
  
In this section, the text-based measure \tkk  is cross-examined with other potentially related measures drawn from existing literature.

Figure \ref{fig:heatmap} presents a correlation matrix that delineates the relationship between the intensity of each topic and the average skill level of employees within a narrowly-defined industry, in accordance with the definition given by Belo et al. (2017). These authors define 'Skill' as the proportion of industry workers engaged in occupations that demand a high degree of training and preparation.

The determination of whether an occupation is high-skill is informed by the Specific Vocational Preparation (SVP) level for each occupation. This data is sourced from the 1991 edition of the Dictionary of Occupational Titles (DOT), published by the U.S. Department of Labor. 

In Belo et al.'s (2017) classification, an occupation is considered high-skill if it possesses an SVP level of 7 or greater. This level implies a requirement of two or more years of preparation. Occupations failing to meet this threshold are classified as low-skill.

\insertfigure{heatmap}{Correlation Matrix Showcasing the Relationship between Topic Intensity and Industry Employee Skill Level}{0.7}

The second component of the analysis, shown in Figure \ref{fig:firmsbypat_hm}, computes the co-occurrences of quartiles for $Topic_{kk}$ and the accumulated patent-related market value within firms, in alignment with the methodology proposed by \cite{Kogan2017-fx}. \cite{Kogan2017-fx} leveraged stock market data to estimate the value of individual patents filed by public corporations since 1926. 

 In Figure \ref{fig:firmsbypat_hm}, the vertical axis signifies annually assigned quartiles of the ratio between Accumulated Patent Value and Total Assets. The results imply a clear correlation between elevated accumulated patent value and increased loadings of $Topic_{kk}$. A basic correlation analysis between average patent intensity and different topics is shown in Figure \ref{fig:heatmap_patents}.

\insertfigure{firmsbypat_hm}{Quartiles of \tkk vs. quartiles of accumulated total patent market value}{0.7}

\insertfigure{heatmap_patents}{Correlation Matrix: Topic Intensities vs. Firms' Patent Intensities}{0.7}

Figure \ref{fig:topicvskkpt_hm} demonstrates the correlation between $Topic_{kk}$ and knowledge capital, as per the definition provided by Peters and Taylor (2017). Notably, it appears that higher accumulated investments in R\&D correspond to increased loadings of $Topic_{kk}$. 

\insertfigure{topicvskkpt_hm}{Correlation Between Knowledge Capital Quartiles and $Topic_{kk}$ Quartiles: Higher R\&D Investments Correlate with Higher Loadings of $Topic_{kk}$}{0.7}

\subsection{Implications for Asset Pricing}

% This subsection needs to be advertised in the introduction and at the beginning of section 3.

In this section, firms are matched based on their Central Index Key (CIK) and Permanent Company Number (PERMNO), facilitating a link between their annual reports and multiple other data sources. These sources encompass daily stock data (aggregated on a weekly basis), Compustat data, and metrics associated with firms' knowledge capital, their cumulative patent value, and the skill level prevalent within their respective industries as delineated in prior literature.

The investigation includes an analysis of value-weighted returns, partitioned according to diverse factors. Figure \ref{fig:awawr} illustrates value-weighted cumulative weekly returns, sorted by quartiles of $Topic_{kk}$ determined on an annual basis. The data signifies a correlation between enhanced $Topic_{kk}$ loadings and amplified weekly returns, a trend particularly prominent from 2011 onwards.

\insertfigure{awawr}{Value-weighted Accumulated Weekly Returns Segregated by Quartiles of $Topic_{kk}$, Showing a Positive Correlation Especially Post-2011}{0.7}

In Figure \ref{fig:awawr_aggind}, when constructing $Topic_{kk}$ quartiles for each yearly-industry subset based on the 12-industry Fama-French classification, the resulting patterns become less interpretable.

\insertfigure{awawr_aggind}{Value-weighted Returns Grouped by Yearly-Industry Subset Quartiles, Indicating Less Interpretable Patterns}{0.7}

Figure \ref{fig:awawr_byg} displays value-weighted accumulated weekly returns, grouped by firms' maximum topic. Notably, firms with the maximum loading on $Topic_{kk}$ (topic 1) have outperformed their peers since 2008.

\insertfigure{awawr_byg}{Firms with Maximum Loading on $Topic_{kk}$ Outperforming Peers Since 2008}{0.7}

Moving on to volatility patterns, Figure \ref{fig:wsdr_byg} presents the weekly standard deviation of returns within groups, categorized by the maximum topic. This analysis suggests that different topics are associated with varying cross-sectional volatility patterns.

\insertfigure{wsdr_byg}{Weekly Standard Deviation of Returns Within Groups, Indicating Variations Across Different Topics}{0.7}

\section{Next steps}

This study is ongoing, with numerous opportunities for enhancement and further exploration. For instance, the hyperparameter selection process could be optimized, potentially through cross-validation techniques. Existing benchmarks for the choice of $k$, such as perplexity, are also being considered for testing.

In addition, the current methodology might evolve towards supervised models. For example, a prior for $Topic_{kk}$ could be imposed, comprising specific words such as ``patents" or ``intellectual property." So far, the learning process has been completely unsupervised.

Another area of interest is testing whether the derived topics can serve as factors in asset pricing models or if they can clarify any anomalies. Moreover, it would be valuable to examine whether the language associated with $Topic_{kk}$ has transformed over time. These areas of focus highlight the promising possibilities for further research and development in this study.

%\insertfigure{heatmap_patents}{Correlation matrix between topics and patent intensity}{0.7}
%
%\FloatBarrier
%\includegraphics[width=0.6\textwidth]{\ffo/awawr_byg.jpg}
%\FloatBarrier
%
%\insertfigure{stackedplot_at}{Stacked plot of firms' total assets in the upper quartile of KK topic intensity}{0.7}
%
%\insertfigure{stackedplot_n}{-}{0.7}
%
%\insertfigure{topicvsikpt_hm}{-}{0.7}
%
%\insertfigure{topicvskkpt_hm}{-}{0.7}

\bibliography{mylibrary2}

\section*{Appendix A: Text conversion to bag-of-words}
\label{bow}

After filtering the firms, I employ the \texttt{spacy} Python library to conduct lemmatization on all the refined texts. Lemmatization transforms words into their base form, ensuring consistent semantics. As an illustration, words such as ``take'', ``took'', and ``taken'' are standardized to ``take''. To do so, \texttt{spacy} leverages WordNet---a comprehensive English lexical database curated by Princeton University.

To extract significant collocations---like ``patent application''---which provide richer semantic insights than individual words, this research adopts the collocation detection method outlined in \cite{Mikolov2013-be}. This methodology yields pertinent bigrams and trigrams. A minimum occurrence threshold of 5 ensures that only the most statistically relevant combinations are incorporated into the dictionary.

This research compiles the entirety of discovered words, bigrams, and trigrams to formulate a dictionary. 

Lastly, the texts are transformed into a bag-of-words model using both the dictionary and the n-gram processed texts. In this representation, each word's frequency in a document, denoted as \(c_{ij}\), is preserved, but the sequence of words is omitted, leading to the final depiction of the corpus.

\begin{figure}[H] % Use [H] to force the figure to be here
  \centering
  \begin{subfigure}{0.45\textwidth}
    \centering
    \includegraphics[width=\textwidth]{cdf_words}
	\caption{Cumulative Distribution of Number of Words}	
    \label{fig:figure1}
  \end{subfigure}
  \hfill
  \begin{subfigure}{0.45\textwidth}
    \centering
    \includegraphics[width=\textwidth]{cdf_words_zoom}
	\caption{Cumulative Distribution of Number of Words, Zoom}
    \label{fig:figure2}
  \end{subfigure}
  \caption{Cumulative Distribution of Number of Words in 2022}
  \label{fig:cdf}
\end{figure}



\end{document} 